{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACM SIGCHI Summer School on Computational Interaction  \n",
    "### Inference, optimization and modeling for the engineering of interactive systems  \n",
    "#### 27th August - 1st September 2018  \n",
    "#### University of Cambridge, UK  \n",
    "\n",
    "<img src=\"imgs/logo.png\" width=\"10%\">\n",
    "\n",
    "# Introduction to unsupervised learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Machine learning can be summarised as making *predictions* from *data*\n",
    "This is slightly distinct from statistics, which is traditionally concerned with making inferences from data -- e.g. determining if an effect is present in a scientific study. Instead, machine learning focuses on trying to estimate the value of unknown variables given some data which might predict them. \n",
    "\n",
    "Machine learning algorithms generally have a *training* phase, where input data is used to update the parameters of a function that tries to model the data, and a *testing* phase, where data unseen by the learning algorithm is used to evaluate how well the model is able to do prediction.\n",
    "\n",
    "##### Machine learning in HCI\n",
    "There are many applications of machine learning techniques in HCI:\n",
    "\n",
    "* **Gesture recognition**. One way to build gesture based systems is to have users perform gestures of different types or classes, record the sensor data from the movements (the *features*) and label the gestures according to their type. A learning algorithm can then learn a function that predicts the gesture type from sensor measurements when subsequently performed.\n",
    "\n",
    "* **Text entry** Language models can be learned from example texts (a corpus) and can then predict likely character sequences to be entered. This can be used to reduce the effort required to enter text.\n",
    "\n",
    "* **Sensor fusion** Many input systems have multiple input sensors (e.g. Kinect + accelerometer). Machine learning can be used to learn a joint space that **fuses** the sensor measurements into a single more reliable measurement, based on observations of co-occuring sensor patterns.\n",
    "\n",
    "* **User modelling** Models of specific aspects of user behaviour (e.g. the offset between intended and actual touch when using a touch screen) can be learned from training data and used to enhance interaction (e.g. by correcting systematic offsets and thus improving apparent accuracy of targeting).\n",
    "\n",
    "### Some mathematical notation\n",
    "\n",
    "We will by considering datasets which consist of a series of measurements. We learn from a *training set* of data.\n",
    "Each measurement is called a *sample* or *datapoint*, and each measurement type is called a *feature*. \n",
    "\n",
    "If we have $n$ samples and $d$ features, we form a matrix $X$ of size $n \\times d$, which has $n$ rows of $d$ measurements. $d$ is the **dimension** of the measurements. $n$ is the **sample size**.  Each row of $X$ is called a *feature vector*. For example, we might have 200 images of digits, each of which is a sequence of $8\\times8=64$ measurements of brightness, giving us a $200 \\times 64$ dataset. The rows of image values are the *features*.\n",
    "\n",
    "In a supervised learning situation, we will also have a vector of *targets* $Y$. These will be the output values we assign to each of the training feature vectors; one target per row of the training features. \n",
    "\n",
    "If we are doing discrete classification, these *targets* will be ordinal *labels* e.g. [0,1]. If we are doing *regression* these will be continuous values. The *targets* can be multi-dimensional (e.g. we could predict two attributes in a regression task), although most common learning tasks have univariate (single-dimensional) targets.\n",
    "\n",
    "We want to learn a function $$y^\\prime = f(x^\\prime)$$ which works for a value $x^\\prime$ that **we have not seen before**; i.e. we want to be able to **predict** a value $y^\\prime$  based on a **model** ($f(x)$) that we learned from data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as axes3d\n",
    "import sklearn.preprocessing, sklearn.cluster, sklearn.tree, sklearn.neighbors, sklearn.ensemble, sklearn.multiclass, sklearn.feature_selection\n",
    "import sklearn.svm, sklearn.cross_validation, sklearn.grid_search, sklearn.metrics, sklearn.datasets, sklearn.decomposition, sklearn.manifold\n",
    "import pandas as pd\n",
    "\n",
    "# force plots to appear inline on this page\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning\n",
    "\n",
    "Supervised learning involves learning a relationship between attribute variables and target variables; in other words learning a function which maps input measurements to target values. This can be in the context of making discrete decisions (is this image a car or not?) or learning continuous relationships (how loud will this aircraft wing be if I make the shape like this?).\n",
    "\n",
    "### Unsupervised learning\n",
    "Unsupervised learning learns the structure of data without any explicit labeling of points. The key idea is that datasets may have a simple underlying or *latent* representation which can be determined simply by looking at the data itself.\n",
    "\n",
    "Two common unsupervised learning tasks are *clustering* and *dimensional reduction*. Clustering can be thought of as the unsupervised analogue of classification -- finding discrete classes in data. Dimensional reduction can be thought of as the analogue of regression -- finding a small set of continuous variables which \"explain\" a higher dimensional set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis\n",
    "One very simple method of dimensional reduction is *principal component analysis*. This is a linear method; in other words it finds rigid rotations and scalings of the data to project it onto a lower dimension. That is, it finds a matrix $A$ such that $y=Ax$ gives a mapping from $d$ dimensional $x$ to $d^\\prime$ dimensional $y$.\n",
    "\n",
    "The PCA algorithm effectively looks for the rotation that makes the dataset look \"fattest\" (maximises the variance), chooses that as the first dimension, then removes that dimension, rotates again to make it look \"fattest\" and repeats. Linear algebra makes it efficient to do this process in a single step by extracting the *eigenvectors* of the *covariance matrix*. \n",
    "\n",
    "PCA always finds a matrix $A$ such that $y = Ax$, where the dimension of $y<x$. PCA is exact and repeatable and very efficient, but it can only find rigid transformations of the data. This is a limitation of any linear dimensional reduction technique.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()\n",
    "digit_data = digits.data\n",
    "\n",
    "# plot a single digit data element\n",
    "def show_digit(d):\n",
    "    plt.imshow(d.reshape(8,8), cmap='gray', interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.figure()\n",
    "    \n",
    "# show a couple of raw digits\n",
    "show_digit(digit_data[0])\n",
    "show_digit(digit_data[400])\n",
    "\n",
    "# apply principal component analysis\n",
    "pca = sklearn.decomposition.PCA(n_components=2).fit(digit_data)\n",
    "digits_2d = pca.transform(digit_data)\n",
    "\n",
    "# plot each digit with a different color\n",
    "plt.scatter(digits_2d[:,0], digits_2d[:,1], c=digits.target, cmap='jet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful property of PCA is that we compute exactly how \"fat\" each of these learned dimensions were. The ratio of *explained variance* tells us how much each of the original variation in the dataset is captured by each learned dimension. \n",
    "\n",
    "If most of the variance is in the first couple of components, we know that a 2D representation will capture much of the original dataset. If the ratios of variance are spread out over many dimensions, we will need many dimensions to represent the data well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see how many dimensions we need to represent the data well using the eigenspectrum\n",
    "# here we show the first 32 components\n",
    "pca = sklearn.decomposition.PCA(n_components=32).fit(digit_data)\n",
    "plt.bar(np.arange(32), pca.explained_variance_ratio_)\n",
    "plt.xlabel(\"Component\")\n",
    "plt.ylabel(\"Proportion of variance explained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example where PCA does badly is the \"swiss roll dataset\" -- a plane rolled up into a spiral in 3D. This has a very simple structure; a simple plane with some distortion. But PCA can never unravel the spiral to find this simple explanation because it cannot be unravelled via a linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_pos, swiss_val = sklearn.datasets.make_swiss_roll(800, noise=0.0)\n",
    "fig = plt.figure()\n",
    "# make a 3D figure\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(swiss_pos[:,0], swiss_pos[:,1], swiss_pos[:,2], c=swiss_val, cmap='gist_heat', s=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to learn this structure (which doesn't help much)\n",
    "pca = sklearn.decomposition.PCA(2).fit(swiss_pos)\n",
    "pca_pos = pca.transform(swiss_pos)\n",
    "plt.scatter(pca_pos[:,0], pca_pos[:,1], c=swiss_val, cmap='gist_heat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manifold learning\n",
    "Other approaches to dimensional reduction look at the problem in terms of learning a *manifold*. A *manifold* is a geometrical structure which is locally like a low-dimensional Euclidean space. Examples are the plane rolled up in the swiss roll, or a 1D \"string\" tangled up in a 3D space. \n",
    "\n",
    "Manifold approaches attempt to automatically find these smooth embedded structures by examining the local structure of datapoints (often by analysing the nearest neighbour graph of points). This is more flexible than linear dimensional reduction as it can in theory unravel very complex or tangled datasets. \n",
    "\n",
    "However, the algorithms are usually approximate, they do not give guarantees that they will find a given manifold, and can be computationally intensive to run.\n",
    "\n",
    "A popular manifold learning algorithm is *ISOMAP* which uses nearest neighbour graphs to identify locally connected parts of a dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap_pos = sklearn.manifold.Isomap(n_neighbors=10, n_components=2).fit_transform(swiss_pos)\n",
    "plt.scatter(isomap_pos[:,0], isomap_pos[:,1], c=swiss_val, cmap='gist_heat')\n",
    "plt.figure()\n",
    "\n",
    "# note that isomap is sensitive to noise!\n",
    "noisy_swiss_pos, swiss_val = sklearn.datasets.make_swiss_roll(800, noise=0.5)\n",
    "isomap_pos = sklearn.manifold.Isomap(n_neighbors=10, n_components=2).fit_transform(noisy_swiss_pos)\n",
    "plt.scatter(isomap_pos[:,0], isomap_pos[:,1], c=swiss_val, cmap='gist_heat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply a more modern dimensional reduction method -- t-distributed stochastic neighbour embedding -- to the digits dataset we used in the PCA example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very slow to run\n",
    "tsne_digits = sklearn.manifold.TSNE(n_components=2).fit_transform(digit_data)\n",
    "plt.scatter(tsne_digits[:,0], tsne_digits[:,1], c=digits.target, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE separates out the digits very nicely into separate regions one for each digit, from the image data alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
