{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ACM SIGCHI Summer School on Computational Interaction  \n",
    "### Inference, optimization and modeling for the engineering of interactive systems  \n",
    "#### 27th August - 1st September 2018  \n",
    "#### University of Cambridge, UK  \n",
    "\n",
    "<img src=\"imgs/logo.png\" width=\"10%\">\n",
    "\n",
    "\n",
    "----\n",
    "# \"Input from the ground up\"\n",
    "\n",
    "## John H. Williamson\n",
    "### University of Glasgow\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\\newcommand{\\vec}[1]{{\\bf #1}} \n",
    "\\newcommand{\\real}{\\mathbb{R}}\n",
    "\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\vec{x}\n",
    "\\real\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "IPython.display.HTML(\"\"\"\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Part 1: The interaction problem\n",
    "\n",
    "One view on interaction is to see user intentions as **unknown values** which are partially observed through input sensors. The time series of inputs from the user only give a partial, noisy, incomplete view of intention inside the user's head. \n",
    "<img src=\"imgs/brain_inference.png\" width=\"100%\">\n",
    "\n",
    "> Interaction is the process of driving a system into a state compatible with user intentions.\n",
    "## Perspectives \n",
    "\n",
    "There are many perspectives on interaction from this stance, including:\n",
    "\n",
    "| Perspective   | Burden | Characteristic                         |\n",
    "|---------------|--------|----------------------------------------|\n",
    "| Communication | User   | User gets information into the system, by encoding intentions. |\n",
    "| Control       | Split  | User drives state towards intention via feedback control.   |\n",
    "| Inference     | System | System infers what user intention is from sensed user actions. |\n",
    "\n",
    "### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a hidden variable: what the user wants a system to do. \n",
    "* **Observations are noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous.\n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">\n",
    "\n",
    "\n",
    "## From the sensors onwards\n",
    "Many of the devices we use for interaction are **designed for interaction**: this includes mice, keyboards, touchscreens etc. They have physical properties which were explicitly created to transduce human physical movement into electrical signals with convenient signal properties that would give efficient control over a computer system.\n",
    "\n",
    "<img src=\"imgs/mouse.png\">\n",
    "\n",
    "A traditional \"roller-ball\" mouse, for example, changes movements of the hand into a pulse train where the pulse count is directly related to the relative motion (ignoring slippage). This is easily counted electronically, and time-integrated to produce a cursor location.\n",
    "\n",
    "But increasingly we will be faced with sensors which either are not explicitly designed for interaction (**xxx name**) or those which may be designed for interaction but cannot be interpreted so simply (**xxx name**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the familiar unfamiliar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
