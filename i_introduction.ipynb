{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "![ACM SIGCHI Summer School on Computational Interaction  \n",
    "Inference, optimization and modeling for the engineering of interactive systems  \n",
    "27th August - 1st September 2018  \n",
    "University of Cambridge, UK  ](imgs/logo_full.png)\n",
    "\n",
    "\n",
    "\n",
    "$$\\newcommand{\\vec}[1]{{\\bf #1} } \n",
    "\\newcommand{\\real}{\\mathbb{R} }\n",
    "\\newcommand{\\expect}[1]{\\mathbb{E}[#1]}\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "\\vec{x}\n",
    "\\real\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "# Unsupervised learning and probabilistic filtering in HCI\n",
    "\n",
    "## John H. Williamson / University of Glasgow\n",
    "<img src=\"imgs/jhw.png\" width=\"200px\">\n",
    "<img src=\"imgs/uog_colour.png\" width=\"200px\">\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Part 1: Unsupervised learning\n",
    "* Introduction to unsupervised learning and vector spaces\n",
    "* Efficient data collection and semi-supervised mapping\n",
    "* **Practical 1**\n",
    "    * Finding order with clustering\n",
    "* Manifold learning\n",
    "* **Practical 2**\n",
    "    * Finding order with manifold learning\n",
    "    \n",
    "## Part 2: Inferring state probabilistically\n",
    "* Intro to probabilistic inference\n",
    "* Interaction as inference\n",
    "* Stochastic filters and the Kalman filter\n",
    "* **Practical 3**\n",
    "    * Solving the noisy cursor problem\n",
    "* Bringing it together\n",
    "* **Practical 4**\n",
    "    * An unusual hand tracker\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the purpose of this course?\n",
    "\n",
    "This course aims to to take a fresh look at how computers determine what users want to do. We will examine machine learning approaches to inferring user intention from observed sensor signals.\n",
    "\n",
    "After this course, you should be able to:\n",
    "* Have a fundamental understanding of the input problem;\n",
    "* Understand the ways in which human-input sensors can vary;\n",
    "* Use unsupervised learning to learn **manifolds** or **clustering** which might explain apparently complex behaviour.\n",
    "* How to attach manifolds of control (\"compressed\" versions of things that are sensed) to action spaces (things we might want to do)\n",
    "* Use probabilistic inference to **reliably** infer and track an action states\n",
    "* Use probabilistic models to accumulate information from the user reliably and efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical details\n",
    "We will be using Jupyter notebooks with Python 2.7. These exercises will work best if you can run them on a local machine. See [requirements.txt](binder/requirements.txt) for a list of the packages we use. \n",
    "\n",
    "On top of Anaconda, we will need:\n",
    "* keyboard\n",
    "* opencv\n",
    "* pykalman\n",
    "\n",
    "#### Keyboard\n",
    "The only special one is [**keyboard**](https://github.com/boppreh/keyboard) which we will use to directly hook the keyboard input. This works on Windows, Linux, and potentially on OS X (but untested on that platform).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "# What is Computational Interaction?\n",
    "Computational interaction applies computational thinking (abstraction, automation, analysis) to explain and enhance interaction between a user and a system. It is underpinned by modelling which admits formal reasoning, and which is amenable to computational approaches.\n",
    "\n",
    "Computational interaction draws on insight from machine learning, signal processing, information theory, optimisation, Bayesian inference, control theory and formal modelling . It emphasises generating motor themes in HCI, and robust, replicable and durable approaches which go beyond point sampling of the interaction space.\n",
    "\n",
    "### Computational interaction would typically involve at least one of:\n",
    "* I. an explicit mathematical model of user-system behavior;\n",
    "* II. a way of updating that model with observed data from users;\n",
    "* III. an algorithmic element that, using this model, can directly synthesise or adapt the\n",
    "design;\n",
    "* IV. a way of automating and instrumenting the modeling and design process;\n",
    "* V. the ability to simulate or synthesise elements of the expected user-system behavior.\n",
    "\n",
    "Computational interaction often involves elements from machine learning, signal processing, information theory,\n",
    "optimisation, inference, control theory and formal modelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# The interaction problem\n",
    "\n",
    "One view on interaction is to see user intentions as **unknown values** which are partially observed through input sensors. The time series of inputs from the user only give a partial, noisy, incomplete view of intention inside the user's head. \n",
    "<img src=\"imgs/brain_inference.png\" width=\"100%\">\n",
    "\n",
    "> Interaction is the process of driving a system into a state compatible with user intentions.\n",
    "## Perspectives \n",
    "\n",
    "There are many perspectives on interaction from this stance, including:\n",
    "\n",
    "| Perspective   | Burden | Characteristic                         |\n",
    "|---------------|--------|----------------------------------------|\n",
    "| Communication | User   | User gets information into the system, by encoding intentions. |\n",
    "| Control       | Split  | User drives state towards intention via feedback control.   |\n",
    "| Inference     | System | System infers what user intention is from sensed user actions. |\n",
    "\n",
    "### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a hidden variable: what the user wants a system to do. \n",
    "* **Observations are noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous.\n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">\n",
    "\n",
    "\n",
    "## From the sensors onwards\n",
    "Many of the devices we use for interaction are **designed for interaction**: this includes mice, keyboards, touchscreens etc. They have physical properties which were explicitly created to transduce human physical movement into electrical signals with convenient signal properties that would give efficient control over a computer system.\n",
    "\n",
    "<img src=\"imgs/mouse.png\">\n",
    "\n",
    "A traditional \"roller-ball\" mouse, for example, changes movements of the hand into a pulse train where the pulse count is directly related to the relative motion (ignoring slippage). This is easily counted electronically, and time-integrated to produce a cursor location on screen. A little bit of transfer function manipulation is used to create an efficiently controllable output which is compatible with the dynamics of human arm motion while seated.\n",
    "\n",
    "But increasingly we will be faced with sensors which either:\n",
    "* are not explicitly designed for interaction: For example, interacting by rubbing the surface of a mobile device and using the audio to control functions\n",
    "<img src=\"imgs/stane.jpg\">\n",
    "*[The Stane, by Murray-Smith et. al](http://www.dcs.gla.ac.uk/~rod/publications/MurWilHugQua08.pdf)*\n",
    "\n",
    "* or those which may be designed for interaction but cannot be interpreted so simply, like a high-degree-of-freedom sensor such as the output of a whole-body pose-tracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/dense_pose.jpg\">\n",
    "*[DensePose, by Riza Alp Gueler, Natalia Neverova, Iasonas Kokkinos](http://densepose.org)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying machine learning\n",
    "Instead of hand-engineering interactions, we can apply machine learning to help us build efficient and usable interfaces. We will look at two aspects of this process today:\n",
    "\n",
    "* How we can do **data-driven** extraction of regularities from sensor signals, and use that to form input devices which are then precisely adapted -- by design -- for use in controlling computer systems. We will look at unsupervised learning as a way to bootstrap this process.\n",
    "\n",
    "* How we can use **probabilistic filtering** to rigorously define the interaction problem as probabilistic inference, and derive practical algorithms that can be fuse together input device signals across time and across sensors channels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
